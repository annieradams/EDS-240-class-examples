---
title: "Lecture 3.3"
format: html
editor: visual
---

```{r}
library(tidycensus)
library(tidyverse)
library(janitor)
library(gghighlight)
```

```{r}

source(here::here("week3", "KEYS.R"))
census_api_key(censusKEY)
```

```{r}
lyme <- read_csv(here::here("week3", "data", "LD-Case-Counts-by-County-01-20.csv"))
```

```{r}
#............wide to long (plus some other wrangling)............
lyme_clean <- lyme |> 
  
  # make col names snake_case ----
  janitor::clean_names() |> 
  
  # rename columns ----
  rename(city = ctyname, state = stname, status = ststatus) |> 
  
  # wide to long (tidy) years
  pivot_longer(cols = 6:25, names_to = "city_year", values_to = "reported_cases") |> 
  
  # remove "cases" from the year & coerce year from chr to factor ----
  mutate(year = str_remove(city_year, pattern = "cases"),
         year = as.factor(year)) |> 
  
  # select necessary cols ----
  select(year, city, state, status, reported_cases)

#................calculate total cases per state.................
lyme_by_state <- lyme_clean |> 
  group_by(year, state) |> 
  summarize(total_cases = sum(reported_cases)) 

##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                      request / wrangle population data                   ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#...................get pop estimates by state...................
us_state_pop <- get_estimates(geography = "state", 
                              product = "population",
                              state = NULL, 
                              year = 2019) |> 
  filter(variable == "POP") |> 
  select(state = NAME, population = value) 

#........................write data to csv.......................
# optional, but recommended in case you want to work offline, the API is down, etc. (you can then read in your saved data file rather than run the above code)
# write_csv(us_state_pop, file = here::here("week3", "dat
```
